{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лабораторная работа №3. Реализация сверточной нейронной сети\n",
    "\n",
    "Данные: В работе предлагается использовать набор данных notMNIST, который состоит из изображений размерностью 28×28 первых 10 букв латинского алфавита (A … J, соответственно). Обучающая выборка содержит порядка 500 тыс. изображений, а тестовая – около 19 тыс.  \n",
    "\n",
    "Данные можно скачать по ссылке:\n",
    "https://commondatastorage.googleapis.com/books1000/notMNIST_large.tar.gz (большой набор данных);  \n",
    "https://commondatastorage.googleapis.com/books1000/notMNIST_small.tar.gz (маленький набор данных);  \n",
    "\n",
    "Описание данных на английском языке доступно по ссылке:  \n",
    "http://yaroslavvb.blogspot.sg/2011/09/notmnist-dataset.html\n",
    "\n",
    "Задание 1.  \n",
    "Реализуйте нейронную сеть с двумя сверточными слоями, и одним полносвязным с нейронами с кусочно-линейной функцией активации. Какова точность построенное модели?\n",
    "\n",
    "Задание 2.  \n",
    "Замените один из сверточных слоев на слой, реализующий операцию пулинга (Pooling) с функцией максимума или среднего. Как это повлияло на точность классификатора?\n",
    "\n",
    "Задание 3.  \n",
    "Реализуйте классическую архитектуру сверточных сетей LeNet-5 (http://yann.lecun.com/exdb/lenet/).\n",
    "\n",
    "Задание 4.  \n",
    "Сравните максимальные точности моделей, построенных в лабораторных работах 1-3. Как можно объяснить полученные различия?\n",
    "\n",
    "Результат выполнения заданий опишите в отчете.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import extract_dataset, download_dataset, read_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://commondatastorage.googleapis.com/books1000/notMNIST_large.tar.gz\"\n",
    "dataset_path = extract_dataset(download_dataset(dataset_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 28, 28\n",
    "known_classes=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"]\n",
    "X, y = read_dataset(dataset_path, known_classes, img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(529114, 28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape((-1, 28, 28, 1))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(529114, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.T\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "epochs_num = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовая сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subset_idx = np.random.choice(np.arange(0, X_train.shape[0]), size=100000, replace=False)\n",
    "X_train = X_train[train_subset_idx, ...]\n",
    "Y_train = Y_train[train_subset_idx, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100000/100000 [==============================] - 40s 398us/step - loss: 2.2491 - acc: 0.1488\n",
      "Epoch 2/25\n",
      "100000/100000 [==============================] - 39s 387us/step - loss: 2.2058 - acc: 0.1697\n",
      "Epoch 3/25\n",
      "100000/100000 [==============================] - 38s 383us/step - loss: 2.1766 - acc: 0.1848\n",
      "Epoch 4/25\n",
      "100000/100000 [==============================] - 39s 394us/step - loss: 2.1416 - acc: 0.2033\n",
      "Epoch 5/25\n",
      "100000/100000 [==============================] - 41s 405us/step - loss: 2.0995 - acc: 0.2252\n",
      "Epoch 6/25\n",
      "100000/100000 [==============================] - 39s 395us/step - loss: 2.0480 - acc: 0.2499\n",
      "Epoch 7/25\n",
      "100000/100000 [==============================] - 39s 390us/step - loss: 1.9827 - acc: 0.2763\n",
      "Epoch 8/25\n",
      "100000/100000 [==============================] - 40s 400us/step - loss: 1.9004 - acc: 0.3101\n",
      "Epoch 9/25\n",
      "100000/100000 [==============================] - 40s 401us/step - loss: 1.8079 - acc: 0.3449\n",
      "Epoch 10/25\n",
      "100000/100000 [==============================] - 41s 406us/step - loss: 1.7113 - acc: 0.3787\n",
      "Epoch 11/25\n",
      "100000/100000 [==============================] - 40s 402us/step - loss: 1.6249 - acc: 0.4078\n",
      "Epoch 12/25\n",
      "100000/100000 [==============================] - 41s 406us/step - loss: 1.5504 - acc: 0.4326\n",
      "Epoch 13/25\n",
      "100000/100000 [==============================] - 42s 415us/step - loss: 1.4811 - acc: 0.4539\n",
      "Epoch 14/25\n",
      "100000/100000 [==============================] - 41s 405us/step - loss: 1.4195 - acc: 0.4773\n",
      "Epoch 15/25\n",
      "100000/100000 [==============================] - 41s 413us/step - loss: 1.3675 - acc: 0.4925\n",
      "Epoch 16/25\n",
      "100000/100000 [==============================] - 42s 424us/step - loss: 1.3226 - acc: 0.5103\n",
      "Epoch 17/25\n",
      "100000/100000 [==============================] - 41s 415us/step - loss: 1.2845 - acc: 0.5250\n",
      "Epoch 18/25\n",
      "100000/100000 [==============================] - 42s 416us/step - loss: 1.2513 - acc: 0.5355\n",
      "Epoch 19/25\n",
      "100000/100000 [==============================] - 41s 412us/step - loss: 1.2234 - acc: 0.5443\n",
      "Epoch 20/25\n",
      "100000/100000 [==============================] - 41s 412us/step - loss: 1.1957 - acc: 0.5554\n",
      "Epoch 21/25\n",
      "100000/100000 [==============================] - 41s 408us/step - loss: 1.1720 - acc: 0.5644\n",
      "Epoch 22/25\n",
      "100000/100000 [==============================] - 41s 413us/step - loss: 1.1515 - acc: 0.5708\n",
      "Epoch 23/25\n",
      "100000/100000 [==============================] - 42s 423us/step - loss: 1.1335 - acc: 0.5771\n",
      "Epoch 24/25\n",
      "100000/100000 [==============================] - 42s 421us/step - loss: 1.1159 - acc: 0.5833\n",
      "Epoch 25/25\n",
      "100000/100000 [==============================] - 42s 417us/step - loss: 1.0991 - acc: 0.5906\n",
      "52912/52912 [==============================] - 6s 106us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.081772766338218, 0.13182264892651951]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(8, (3, 3), activation='relu', input_shape=(img_height, img_width, 1)),\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),        \n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train, epochs=epochs_num)\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С MaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "100000/100000 [==============================] - 14s 144us/step - loss: 2.2581 - acc: 0.1487\n",
      "Epoch 2/25\n",
      "100000/100000 [==============================] - 14s 142us/step - loss: 2.2185 - acc: 0.1638\n",
      "Epoch 3/25\n",
      "100000/100000 [==============================] - 14s 141us/step - loss: 2.1997 - acc: 0.1713\n",
      "Epoch 4/25\n",
      "100000/100000 [==============================] - 14s 143us/step - loss: 2.1870 - acc: 0.1753\n",
      "Epoch 5/25\n",
      "100000/100000 [==============================] - 14s 142us/step - loss: 2.1772 - acc: 0.1789\n",
      "Epoch 6/25\n",
      "100000/100000 [==============================] - 14s 142us/step - loss: 2.1646 - acc: 0.1844\n",
      "Epoch 7/25\n",
      "100000/100000 [==============================] - 14s 141us/step - loss: 2.1529 - acc: 0.1898\n",
      "Epoch 8/25\n",
      "100000/100000 [==============================] - 14s 142us/step - loss: 2.1443 - acc: 0.1944\n",
      "Epoch 9/25\n",
      "100000/100000 [==============================] - 14s 143us/step - loss: 2.1349 - acc: 0.1983\n",
      "Epoch 10/25\n",
      "100000/100000 [==============================] - 14s 141us/step - loss: 2.1255 - acc: 0.2044\n",
      "Epoch 11/25\n",
      "100000/100000 [==============================] - 14s 142us/step - loss: 2.1156 - acc: 0.2074\n",
      "Epoch 12/25\n",
      "100000/100000 [==============================] - 14s 143us/step - loss: 2.1049 - acc: 0.2117\n",
      "Epoch 13/25\n",
      "100000/100000 [==============================] - 14s 141us/step - loss: 2.0950 - acc: 0.2146\n",
      "Epoch 14/25\n",
      "100000/100000 [==============================] - 14s 142us/step - loss: 2.0842 - acc: 0.2191\n",
      "Epoch 15/25\n",
      "100000/100000 [==============================] - 14s 142us/step - loss: 2.0745 - acc: 0.2212\n",
      "Epoch 16/25\n",
      "100000/100000 [==============================] - 14s 142us/step - loss: 2.0639 - acc: 0.2261\n",
      "Epoch 17/25\n",
      "100000/100000 [==============================] - 14s 141us/step - loss: 2.0540 - acc: 0.2307\n",
      "Epoch 18/25\n",
      "100000/100000 [==============================] - 14s 142us/step - loss: 2.0431 - acc: 0.2358\n",
      "Epoch 19/25\n",
      "100000/100000 [==============================] - 14s 141us/step - loss: 2.0344 - acc: 0.2396\n",
      "Epoch 20/25\n",
      "100000/100000 [==============================] - 14s 142us/step - loss: 2.0245 - acc: 0.2420\n",
      "Epoch 21/25\n",
      "100000/100000 [==============================] - 14s 141us/step - loss: 2.0160 - acc: 0.2449\n",
      "Epoch 22/25\n",
      "100000/100000 [==============================] - 14s 142us/step - loss: 2.0063 - acc: 0.2488\n",
      "Epoch 23/25\n",
      "100000/100000 [==============================] - 14s 141us/step - loss: 1.9999 - acc: 0.2500\n",
      "Epoch 24/25\n",
      "100000/100000 [==============================] - 14s 142us/step - loss: 1.9908 - acc: 0.2546\n",
      "Epoch 25/25\n",
      "100000/100000 [==============================] - 14s 142us/step - loss: 1.9848 - acc: 0.2561\n",
      "52912/52912 [==============================] - 3s 62us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4995180212337518, 0.16039839733897793]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(8, (3, 3), activation='relu', input_shape=(img_height, img_width, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),        \n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train, epochs=epochs_num)\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le-Net 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100000/100000 [==============================] - 22s 221us/step - loss: 2.2582 - acc: 0.1482\n",
      "Epoch 2/50\n",
      "100000/100000 [==============================] - 22s 218us/step - loss: 2.2341 - acc: 0.1589\n",
      "Epoch 3/50\n",
      "100000/100000 [==============================] - 22s 218us/step - loss: 2.2080 - acc: 0.1657\n",
      "Epoch 4/50\n",
      "100000/100000 [==============================] - 23s 226us/step - loss: 2.1874 - acc: 0.1768\n",
      "Epoch 5/50\n",
      "100000/100000 [==============================] - 23s 226us/step - loss: 2.1730 - acc: 0.1821\n",
      "Epoch 6/50\n",
      "100000/100000 [==============================] - 21s 212us/step - loss: 2.1594 - acc: 0.1859\n",
      "Epoch 7/50\n",
      "100000/100000 [==============================] - 21s 212us/step - loss: 2.1498 - acc: 0.1928\n",
      "Epoch 8/50\n",
      "100000/100000 [==============================] - 21s 212us/step - loss: 2.1427 - acc: 0.1949\n",
      "Epoch 9/50\n",
      "100000/100000 [==============================] - 21s 208us/step - loss: 2.1357 - acc: 0.1973\n",
      "Epoch 10/50\n",
      "100000/100000 [==============================] - 21s 207us/step - loss: 2.1285 - acc: 0.1990\n",
      "Epoch 11/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 2.1238 - acc: 0.2016\n",
      "Epoch 12/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 2.1202 - acc: 0.2027\n",
      "Epoch 13/50\n",
      "100000/100000 [==============================] - 21s 210us/step - loss: 2.1152 - acc: 0.2064\n",
      "Epoch 14/50\n",
      "100000/100000 [==============================] - 21s 212us/step - loss: 2.1106 - acc: 0.2075\n",
      "Epoch 15/50\n",
      "100000/100000 [==============================] - 21s 208us/step - loss: 2.1060 - acc: 0.2105\n",
      "Epoch 16/50\n",
      "100000/100000 [==============================] - 21s 215us/step - loss: 2.1005 - acc: 0.2118\n",
      "Epoch 17/50\n",
      "100000/100000 [==============================] - 21s 215us/step - loss: 2.0968 - acc: 0.2146\n",
      "Epoch 18/50\n",
      "100000/100000 [==============================] - 21s 207us/step - loss: 2.0899 - acc: 0.2164\n",
      "Epoch 19/50\n",
      "100000/100000 [==============================] - 21s 207us/step - loss: 2.0859 - acc: 0.2171\n",
      "Epoch 20/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 2.0820 - acc: 0.2194\n",
      "Epoch 21/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 2.0762 - acc: 0.2216\n",
      "Epoch 22/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 2.0712 - acc: 0.2235\n",
      "Epoch 23/50\n",
      "100000/100000 [==============================] - 21s 210us/step - loss: 2.0651 - acc: 0.2248\n",
      "Epoch 24/50\n",
      "100000/100000 [==============================] - 21s 207us/step - loss: 2.0605 - acc: 0.2272\n",
      "Epoch 25/50\n",
      "100000/100000 [==============================] - 21s 207us/step - loss: 2.0560 - acc: 0.2281\n",
      "Epoch 26/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 2.0511 - acc: 0.2309\n",
      "Epoch 27/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 2.0453 - acc: 0.2317\n",
      "Epoch 28/50\n",
      "100000/100000 [==============================] - 21s 208us/step - loss: 2.0400 - acc: 0.2340\n",
      "Epoch 29/50\n",
      "100000/100000 [==============================] - 21s 208us/step - loss: 2.0372 - acc: 0.2368\n",
      "Epoch 30/50\n",
      "100000/100000 [==============================] - 21s 208us/step - loss: 2.0302 - acc: 0.2395\n",
      "Epoch 31/50\n",
      "100000/100000 [==============================] - 21s 207us/step - loss: 2.0256 - acc: 0.2415\n",
      "Epoch 32/50\n",
      "100000/100000 [==============================] - 21s 208us/step - loss: 2.0192 - acc: 0.2445\n",
      "Epoch 33/50\n",
      "100000/100000 [==============================] - 21s 210us/step - loss: 2.0172 - acc: 0.2445\n",
      "Epoch 34/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 2.0121 - acc: 0.2479\n",
      "Epoch 35/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 2.0073 - acc: 0.2494\n",
      "Epoch 36/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 2.0036 - acc: 0.2514\n",
      "Epoch 37/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 1.9994 - acc: 0.2532\n",
      "Epoch 38/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 1.9959 - acc: 0.2534\n",
      "Epoch 39/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 1.9897 - acc: 0.2563\n",
      "Epoch 40/50\n",
      "100000/100000 [==============================] - 21s 208us/step - loss: 1.9873 - acc: 0.2604\n",
      "Epoch 41/50\n",
      "100000/100000 [==============================] - 21s 205us/step - loss: 1.9819 - acc: 0.2594\n",
      "Epoch 42/50\n",
      "100000/100000 [==============================] - 21s 207us/step - loss: 1.9777 - acc: 0.2615\n",
      "Epoch 43/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 1.9782 - acc: 0.2618\n",
      "Epoch 44/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 1.9722 - acc: 0.2625\n",
      "Epoch 45/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 1.9684 - acc: 0.2653\n",
      "Epoch 46/50\n",
      "100000/100000 [==============================] - 21s 205us/step - loss: 1.9637 - acc: 0.2675\n",
      "Epoch 47/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 1.9627 - acc: 0.2689\n",
      "Epoch 48/50\n",
      "100000/100000 [==============================] - 21s 206us/step - loss: 1.9584 - acc: 0.2704\n",
      "Epoch 49/50\n",
      "100000/100000 [==============================] - 21s 205us/step - loss: 1.9558 - acc: 0.2710\n",
      "Epoch 50/50\n",
      "100000/100000 [==============================] - 21s 205us/step - loss: 1.9509 - acc: 0.2723\n",
      "52912/52912 [==============================] - 5s 87us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1740887024484086, 0.19579679467795585]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "        tf.keras.layers.Conv2D(filters=16, kernel_size=(5, 5), activation='relu'),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "        tf.keras.layers.Flatten(),        \n",
    "        tf.keras.layers.Dense(120, activation='relu'),\n",
    "        tf.keras.layers.Dense(84, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train, epochs=epochs_num * 2)\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты изначальной модели. Агрессивный average pooling усложняет обучение, увеличение количества эпох в два раза не приводик к значительному улучшению результата."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
