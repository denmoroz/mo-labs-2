{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лабораторная работа №2. Реализация глубокой нейронной сети\n",
    "\n",
    "Данные: В работе предлагается использовать набор данных notMNIST, который состоит из изображений размерностью 28×28 первых 10 букв латинского алфавита (A … J, соответственно). Обучающая выборка содержит порядка 500 тыс. изображений, а тестовая – около 19 тыс.\n",
    "\n",
    "Данные можно скачать по ссылке:\n",
    "https://commondatastorage.googleapis.com/books1000/notMNIST_large.tar.gz (большой набор данных);\n",
    "https://commondatastorage.googleapis.com/books1000/notMNIST_small.tar.gz (маленький набор данных);\n",
    "\n",
    "Описание данных на английском языке доступно по ссылке:\n",
    "http://yaroslavvb.blogspot.sg/2011/09/notmnist-dataset.html\n",
    "\n",
    "Задание 1.\n",
    "Реализуйте полносвязную нейронную сеть с помощью библиотеки Tensor Flow. В качестве алгоритма оптимизации можно использовать, например, стохастический градиент (Stochastic Gradient Descent, SGD). Определите количество скрытых слоев от 1 до 5, количество нейронов в каждом из слоев до нескольких сотен, а также их функции активации (кусочно-линейная, сигмоидная, гиперболический тангенс и т.д.).\n",
    "\n",
    "Задание 2.\n",
    "Как улучшилась точность классификатора по сравнению с логистической регрессией?\n",
    "\n",
    "Задание 3.\n",
    "Используйте регуляризацию и метод сброса нейронов (dropout) для борьбы с переобучением. Как улучшилось качество классификации?\n",
    "\n",
    "Задание 4.\n",
    "Воспользуйтесь динамически изменяемой скоростью обучения (learning rate). Наилучшая точность, достигнутая с помощью данной модели составляет 97.1%. Какую точность демонстрирует Ваша реализованная модель?\n",
    "\n",
    "Результат выполнения заданий опишите в отчете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import extract_dataset, download_dataset, read_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://commondatastorage.googleapis.com/books1000/notMNIST_large.tar.gz\"\n",
    "dataset_path = extract_dataset(download_dataset(dataset_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 28, 28\n",
    "known_classes=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"]\n",
    "X, y = read_dataset(dataset_path, known_classes, img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X.T, y.T, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((423291, 784), (105823, 784))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "num_epochs = 50\n",
    "batch_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 423291 samples\n",
      "Epoch 1/50\n",
      "423291/423291 [==============================] - 2s 5us/sample - loss: 0.5527 - accuracy: 0.8402\n",
      "Epoch 2/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.4086 - accuracy: 0.8780\n",
      "Epoch 3/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.3658 - accuracy: 0.8907\n",
      "Epoch 4/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.3398 - accuracy: 0.8976\n",
      "Epoch 5/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.3216 - accuracy: 0.9027\n",
      "Epoch 6/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.3069 - accuracy: 0.9071\n",
      "Epoch 7/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2948 - accuracy: 0.9104\n",
      "Epoch 8/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2854 - accuracy: 0.9130\n",
      "Epoch 9/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2764 - accuracy: 0.9156\n",
      "Epoch 10/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2694 - accuracy: 0.9177\n",
      "Epoch 11/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2621 - accuracy: 0.9199\n",
      "Epoch 12/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2552 - accuracy: 0.9218\n",
      "Epoch 13/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2492 - accuracy: 0.9236\n",
      "Epoch 14/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2445 - accuracy: 0.9250\n",
      "Epoch 15/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2394 - accuracy: 0.9262\n",
      "Epoch 16/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2351 - accuracy: 0.9279\n",
      "Epoch 17/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2313 - accuracy: 0.9289\n",
      "Epoch 18/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2260 - accuracy: 0.9304\n",
      "Epoch 19/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2229 - accuracy: 0.9313\n",
      "Epoch 20/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2189 - accuracy: 0.9325\n",
      "Epoch 21/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2153 - accuracy: 0.9335\n",
      "Epoch 22/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2118 - accuracy: 0.9346\n",
      "Epoch 23/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2089 - accuracy: 0.9357\n",
      "Epoch 24/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2054 - accuracy: 0.9367\n",
      "Epoch 25/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2030 - accuracy: 0.9371\n",
      "Epoch 26/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.2003 - accuracy: 0.9382\n",
      "Epoch 27/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.1975 - accuracy: 0.9387\n",
      "Epoch 28/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.1941 - accuracy: 0.9402\n",
      "Epoch 29/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.1920 - accuracy: 0.9406\n",
      "Epoch 30/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.1897 - accuracy: 0.9411\n",
      "Epoch 31/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.1869 - accuracy: 0.9421\n",
      "Epoch 32/50\n",
      "423291/423291 [==============================] - 1s 2us/sample - loss: 0.1850 - accuracy: 0.9425\n",
      "Epoch 33/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.1827 - accuracy: 0.9432\n",
      "Epoch 34/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.1796 - accuracy: 0.9440\n",
      "Epoch 35/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.1790 - accuracy: 0.9444\n",
      "Epoch 36/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.1762 - accuracy: 0.9453\n",
      "Epoch 37/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.1743 - accuracy: 0.9460\n",
      "Epoch 38/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.1725 - accuracy: 0.9463\n",
      "Epoch 39/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.1700 - accuracy: 0.9472\n",
      "Epoch 40/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.1687 - accuracy: 0.9475\n",
      "Epoch 41/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.1662 - accuracy: 0.9482\n",
      "Epoch 42/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.1663 - accuracy: 0.9485\n",
      "Epoch 43/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.1637 - accuracy: 0.9490\n",
      "Epoch 44/50\n",
      "423291/423291 [==============================] - 1s 4us/sample - loss: 0.1628 - accuracy: 0.9494\n",
      "Epoch 45/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.1597 - accuracy: 0.9504\n",
      "Epoch 46/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.1590 - accuracy: 0.9505\n",
      "Epoch 47/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.1578 - accuracy: 0.9509\n",
      "Epoch 48/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.1561 - accuracy: 0.9511\n",
      "Epoch 49/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.1540 - accuracy: 0.9520\n",
      "Epoch 50/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.1531 - accuracy: 0.9525\n",
      "105823/105823 [==============================] - 6s 59us/sample - loss: 0.3789 - accuracy: 0.9088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3788711062558126, 0.90881944]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train, epochs=num_epochs, batch_size=batch_size)\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 423291 samples\n",
      "Epoch 1/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.6134 - accuracy: 0.8303\n",
      "Epoch 2/50\n",
      "423291/423291 [==============================] - 1s 4us/sample - loss: 0.4657 - accuracy: 0.8716\n",
      "Epoch 3/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.4274 - accuracy: 0.8823\n",
      "Epoch 4/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.4060 - accuracy: 0.8882\n",
      "Epoch 5/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3897 - accuracy: 0.8923\n",
      "Epoch 6/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3798 - accuracy: 0.8950\n",
      "Epoch 7/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3722 - accuracy: 0.8969\n",
      "Epoch 8/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3647 - accuracy: 0.8993\n",
      "Epoch 9/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3585 - accuracy: 0.9010\n",
      "Epoch 10/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3544 - accuracy: 0.9020\n",
      "Epoch 11/50\n",
      "423291/423291 [==============================] - 1s 4us/sample - loss: 0.3514 - accuracy: 0.9025\n",
      "Epoch 12/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3472 - accuracy: 0.9042\n",
      "Epoch 13/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3444 - accuracy: 0.9052\n",
      "Epoch 14/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3422 - accuracy: 0.9057\n",
      "Epoch 15/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3394 - accuracy: 0.9063\n",
      "Epoch 16/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3364 - accuracy: 0.9072\n",
      "Epoch 17/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3345 - accuracy: 0.9078\n",
      "Epoch 18/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3333 - accuracy: 0.9081\n",
      "Epoch 19/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3321 - accuracy: 0.9084\n",
      "Epoch 20/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3315 - accuracy: 0.9088\n",
      "Epoch 21/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3287 - accuracy: 0.9096\n",
      "Epoch 22/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3278 - accuracy: 0.9096\n",
      "Epoch 23/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3274 - accuracy: 0.9098\n",
      "Epoch 24/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3261 - accuracy: 0.9104\n",
      "Epoch 25/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3249 - accuracy: 0.9106\n",
      "Epoch 26/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3242 - accuracy: 0.9110\n",
      "Epoch 27/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3233 - accuracy: 0.9114\n",
      "Epoch 28/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3229 - accuracy: 0.9112\n",
      "Epoch 29/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3214 - accuracy: 0.9116\n",
      "Epoch 30/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3212 - accuracy: 0.9119\n",
      "Epoch 31/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3198 - accuracy: 0.9124\n",
      "Epoch 32/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3189 - accuracy: 0.9124\n",
      "Epoch 33/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3179 - accuracy: 0.9130\n",
      "Epoch 34/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3176 - accuracy: 0.9130\n",
      "Epoch 35/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3178 - accuracy: 0.9132\n",
      "Epoch 36/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3166 - accuracy: 0.9135\n",
      "Epoch 37/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3162 - accuracy: 0.9136\n",
      "Epoch 38/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3152 - accuracy: 0.9141\n",
      "Epoch 39/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3158 - accuracy: 0.9134\n",
      "Epoch 40/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3143 - accuracy: 0.9139\n",
      "Epoch 41/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3139 - accuracy: 0.9143\n",
      "Epoch 42/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3133 - accuracy: 0.9143\n",
      "Epoch 43/50\n",
      "423291/423291 [==============================] - 1s 4us/sample - loss: 0.3140 - accuracy: 0.9143\n",
      "Epoch 44/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3123 - accuracy: 0.9148\n",
      "Epoch 45/50\n",
      "423291/423291 [==============================] - 1s 4us/sample - loss: 0.3138 - accuracy: 0.9147\n",
      "Epoch 46/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3123 - accuracy: 0.9149\n",
      "Epoch 47/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3119 - accuracy: 0.9147\n",
      "Epoch 48/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3120 - accuracy: 0.9149\n",
      "Epoch 49/50\n",
      "423291/423291 [==============================] - 2s 4us/sample - loss: 0.3120 - accuracy: 0.9149\n",
      "Epoch 50/50\n",
      "423291/423291 [==============================] - 1s 3us/sample - loss: 0.3119 - accuracy: 0.9148\n",
      "105823/105823 [==============================] - 6s 55us/sample - loss: 0.3346 - accuracy: 0.9098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33460342928222403, 0.9097833]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_rate = 0.1\n",
    "l2_regularization = 1e-4\n",
    "\n",
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(l2_regularization)),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(l2_regularization)),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train, epochs=num_epochs, batch_size=batch_size)\n",
    "model.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
