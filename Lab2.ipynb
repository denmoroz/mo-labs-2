{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лабораторная работа №2. Реализация глубокой нейронной сети\n",
    "\n",
    "Данные: В работе предлагается использовать набор данных notMNIST, который состоит из изображений размерностью 28×28 первых 10 букв латинского алфавита (A … J, соответственно). Обучающая выборка содержит порядка 500 тыс. изображений, а тестовая – около 19 тыс.\n",
    "\n",
    "Данные можно скачать по ссылке:\n",
    "https://commondatastorage.googleapis.com/books1000/notMNIST_large.tar.gz (большой набор данных);\n",
    "https://commondatastorage.googleapis.com/books1000/notMNIST_small.tar.gz (маленький набор данных);\n",
    "\n",
    "Описание данных на английском языке доступно по ссылке:\n",
    "http://yaroslavvb.blogspot.sg/2011/09/notmnist-dataset.html\n",
    "\n",
    "Задание 1.\n",
    "Реализуйте полносвязную нейронную сеть с помощью библиотеки Tensor Flow. В качестве алгоритма оптимизации можно использовать, например, стохастический градиент (Stochastic Gradient Descent, SGD). Определите количество скрытых слоев от 1 до 5, количество нейронов в каждом из слоев до нескольких сотен, а также их функции активации (кусочно-линейная, сигмоидная, гиперболический тангенс и т.д.).\n",
    "\n",
    "Задание 2.\n",
    "Как улучшилась точность классификатора по сравнению с логистической регрессией?\n",
    "\n",
    "Задание 3.\n",
    "Используйте регуляризацию и метод сброса нейронов (dropout) для борьбы с переобучением. Как улучшилось качество классификации?\n",
    "\n",
    "Задание 4.\n",
    "Воспользуйтесь динамически изменяемой скоростью обучения (learning rate). Наилучшая точность, достигнутая с помощью данной модели составляет 97.1%. Какую точность демонстрирует Ваша реализованная модель?\n",
    "\n",
    "Результат выполнения заданий опишите в отчете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import extract_dataset, download_dataset, read_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = \"https://commondatastorage.googleapis.com/books1000/notMNIST_large.tar.gz\"\n",
    "dataset_path = extract_dataset(download_dataset(dataset_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = 28, 28\n",
    "known_classes=[\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\"]\n",
    "X, y = read_dataset(dataset_path, known_classes, img_height, img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X.T, y.T, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((476202, 784), (52912, 784))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "476202/476202 [==============================] - 23s 49us/step - loss: 0.4269 - acc: 0.8709\n",
      "Epoch 2/25\n",
      "476202/476202 [==============================] - 23s 49us/step - loss: 0.3404 - acc: 0.8949\n",
      "Epoch 3/25\n",
      "476202/476202 [==============================] - 23s 48us/step - loss: 0.3132 - acc: 0.9023\n",
      "Epoch 4/25\n",
      "476202/476202 [==============================] - 22s 47us/step - loss: 0.2975 - acc: 0.9068\n",
      "Epoch 5/25\n",
      "476202/476202 [==============================] - 23s 47us/step - loss: 0.2851 - acc: 0.9101\n",
      "Epoch 6/25\n",
      "476202/476202 [==============================] - 23s 48us/step - loss: 0.2765 - acc: 0.9126\n",
      "Epoch 7/25\n",
      "476202/476202 [==============================] - 23s 48us/step - loss: 0.2688 - acc: 0.9145\n",
      "Epoch 8/25\n",
      "476202/476202 [==============================] - 23s 48us/step - loss: 0.2628 - acc: 0.9167\n",
      "Epoch 9/25\n",
      "476202/476202 [==============================] - 23s 48us/step - loss: 0.2575 - acc: 0.9182\n",
      "Epoch 10/25\n",
      "476202/476202 [==============================] - 23s 48us/step - loss: 0.2529 - acc: 0.9195\n",
      "Epoch 11/25\n",
      "476202/476202 [==============================] - 23s 49us/step - loss: 0.2480 - acc: 0.9208\n",
      "Epoch 12/25\n",
      "476202/476202 [==============================] - 23s 49us/step - loss: 0.2448 - acc: 0.9215\n",
      "Epoch 13/25\n",
      "476202/476202 [==============================] - 23s 49us/step - loss: 0.2406 - acc: 0.9228\n",
      "Epoch 14/25\n",
      "476202/476202 [==============================] - 23s 48us/step - loss: 0.2375 - acc: 0.9236\n",
      "Epoch 15/25\n",
      "476202/476202 [==============================] - 23s 48us/step - loss: 0.2345 - acc: 0.9243\n",
      "Epoch 16/25\n",
      "476202/476202 [==============================] - 23s 48us/step - loss: 0.2316 - acc: 0.9252\n",
      "Epoch 17/25\n",
      "476202/476202 [==============================] - 23s 48us/step - loss: 0.2295 - acc: 0.9258\n",
      "Epoch 18/25\n",
      "476202/476202 [==============================] - 23s 48us/step - loss: 0.2274 - acc: 0.9265\n",
      "Epoch 19/25\n",
      "476202/476202 [==============================] - 23s 49us/step - loss: 0.2251 - acc: 0.9273\n",
      "Epoch 20/25\n",
      "476202/476202 [==============================] - 23s 48us/step - loss: 0.2226 - acc: 0.9278\n",
      "Epoch 21/25\n",
      "476202/476202 [==============================] - 23s 49us/step - loss: 0.2208 - acc: 0.9285\n",
      "Epoch 22/25\n",
      "476202/476202 [==============================] - 23s 48us/step - loss: 0.2191 - acc: 0.9288\n",
      "Epoch 23/25\n",
      "476202/476202 [==============================] - 23s 49us/step - loss: 0.2171 - acc: 0.9293\n",
      "Epoch 24/25\n",
      "476202/476202 [==============================] - 23s 49us/step - loss: 0.2157 - acc: 0.9302\n",
      "Epoch 25/25\n",
      "476202/476202 [==============================] - 23s 49us/step - loss: 0.2137 - acc: 0.9306\n",
      "52912/52912 [==============================] - 1s 19us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3436522977387485, 0.9094723314182038]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train, epochs=num_epochs)\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "476202/476202 [==============================] - 25s 52us/step - loss: 0.4849 - acc: 0.8688\n",
      "Epoch 2/25\n",
      "476202/476202 [==============================] - 24s 51us/step - loss: 0.4267 - acc: 0.8870\n",
      "Epoch 3/25\n",
      "476202/476202 [==============================] - 24s 51us/step - loss: 0.4151 - acc: 0.8911\n",
      "Epoch 4/25\n",
      "476202/476202 [==============================] - 24s 51us/step - loss: 0.4102 - acc: 0.8924\n",
      "Epoch 5/25\n",
      "476202/476202 [==============================] - 24s 51us/step - loss: 0.4061 - acc: 0.8938\n",
      "Epoch 6/25\n",
      "476202/476202 [==============================] - 24s 51us/step - loss: 0.4030 - acc: 0.8949\n",
      "Epoch 7/25\n",
      "476202/476202 [==============================] - 24s 51us/step - loss: 0.4009 - acc: 0.8953\n",
      "Epoch 8/25\n",
      "476202/476202 [==============================] - 24s 51us/step - loss: 0.3993 - acc: 0.8958\n",
      "Epoch 9/25\n",
      "476202/476202 [==============================] - 24s 51us/step - loss: 0.3979 - acc: 0.8960\n",
      "Epoch 10/25\n",
      "476202/476202 [==============================] - 24s 51us/step - loss: 0.3965 - acc: 0.8965\n",
      "Epoch 11/25\n",
      "476202/476202 [==============================] - 24s 51us/step - loss: 0.3953 - acc: 0.8964\n",
      "Epoch 12/25\n",
      "476202/476202 [==============================] - 24s 51us/step - loss: 0.3944 - acc: 0.8963\n",
      "Epoch 13/25\n",
      "476202/476202 [==============================] - 24s 51us/step - loss: 0.3931 - acc: 0.8968\n",
      "Epoch 14/25\n",
      "476202/476202 [==============================] - 25s 53us/step - loss: 0.3927 - acc: 0.8974\n",
      "Epoch 15/25\n",
      "476202/476202 [==============================] - 25s 53us/step - loss: 0.3917 - acc: 0.8973\n",
      "Epoch 16/25\n",
      "476202/476202 [==============================] - 25s 53us/step - loss: 0.3915 - acc: 0.8972\n",
      "Epoch 17/25\n",
      "476202/476202 [==============================] - 25s 53us/step - loss: 0.3915 - acc: 0.8971\n",
      "Epoch 18/25\n",
      "476202/476202 [==============================] - 25s 53us/step - loss: 0.3903 - acc: 0.8978\n",
      "Epoch 19/25\n",
      "476202/476202 [==============================] - 25s 52us/step - loss: 0.3900 - acc: 0.8980\n",
      "Epoch 20/25\n",
      "476202/476202 [==============================] - 25s 53us/step - loss: 0.3894 - acc: 0.8977\n",
      "Epoch 21/25\n",
      "476202/476202 [==============================] - 25s 53us/step - loss: 0.3885 - acc: 0.8983\n",
      "Epoch 22/25\n",
      "476202/476202 [==============================] - 25s 53us/step - loss: 0.3892 - acc: 0.8980\n",
      "Epoch 23/25\n",
      "476202/476202 [==============================] - 25s 53us/step - loss: 0.3879 - acc: 0.8979\n",
      "Epoch 24/25\n",
      "476202/476202 [==============================] - 25s 53us/step - loss: 0.3876 - acc: 0.8985\n",
      "Epoch 25/25\n",
      "476202/476202 [==============================] - 25s 53us/step - loss: 0.3877 - acc: 0.8982\n",
      "52912/52912 [==============================] - 1s 21us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3995600230192035, 0.8957514363471424]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(128, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
    "    tf.keras.layers.Dropout(0.1),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "model.fit(X_train, Y_train, epochs=num_epochs)\n",
    "model.evaluate(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
